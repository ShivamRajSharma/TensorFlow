{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as alb \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Conv2DTranspose, Dense, BatchNormalization,\n",
    "    GlobalAveragePooling2D, MaxPooling2D, LeakyReLU,\n",
    "    Dropout, Input, Reshape, Conv1D, ReLU\n",
    ")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "image_shape = (64, 64, 3)\n",
    "augmentation = alb.Compose([\n",
    "        alb.CenterCrop(160, 160),\n",
    "        alb.Resize(image_shape[0], image_shape[1], always_apply=True),\n",
    "        alb.Normalize(mean, std, always_apply=True)  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(batch_image_path):\n",
    "    batch_images = []\n",
    "    for path in batch_image_path:\n",
    "        full_path = os.path.join(faces_path, path)\n",
    "        img = np.array(Image.open(full_path).convert('RGB'))\n",
    "        img = augmentation(image=img)['image']\n",
    "        batch_images.append(img)\n",
    "    batch_images = np.array(batch_images)\n",
    "    return batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/thisisiron/spectral_normalization-tf2\n",
    "class SpectralNormalization(tf.keras.layers.Wrapper):\n",
    "    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n",
    "        self.iteration = iteration\n",
    "        self.eps = eps\n",
    "        self.do_power_iteration = training\n",
    "        if not isinstance(layer, tf.keras.layers.Layer):\n",
    "            raise ValueError(\n",
    "                'Please initialize `TimeDistributed` layer with a '\n",
    "                '`Layer` instance. You passed: {input}'.format(input=layer))\n",
    "        super(SpectralNormalization, self).__init__(layer, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.layer.build(input_shape)\n",
    "\n",
    "        self.w = self.layer.kernel\n",
    "        self.w_shape = self.w.shape.as_list()\n",
    "\n",
    "        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n",
    "                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n",
    "                                 trainable=False,\n",
    "                                 name='sn_v',\n",
    "                                 dtype=tf.float32)\n",
    "\n",
    "        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n",
    "                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n",
    "                                 trainable=False,\n",
    "                                 name='sn_u',\n",
    "                                 dtype=tf.float32)\n",
    "\n",
    "        super(SpectralNormalization, self).build()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.update_weights()\n",
    "        output = self.layer(inputs)\n",
    "        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n",
    "        return output\n",
    "    \n",
    "    def update_weights(self):\n",
    "        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n",
    "        \n",
    "        u_hat = self.u\n",
    "        v_hat = self.v  # init v vector\n",
    "\n",
    "        if self.do_power_iteration:\n",
    "            for _ in range(self.iteration):\n",
    "                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n",
    "                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n",
    "\n",
    "                u_ = tf.matmul(v_hat, w_reshaped)\n",
    "                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n",
    "\n",
    "        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n",
    "        self.u.assign(u_hat)\n",
    "        self.v.assign(v_hat)\n",
    "\n",
    "        self.layer.kernel.assign(self.w / sigma)\n",
    "\n",
    "    def restore_weights(self):\n",
    "        self.layer.kernel.assign(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention_block(x):\n",
    "    batch, height, width, channel = x.shape\n",
    "    \n",
    "    key = Conv2D(x.shape[-1], kernel_size=1)(x)\n",
    "    query = Conv2D(x.shape[-1], kernel_size=1)(x)\n",
    "    value = Conv2D(x.shape[-1], kernel_size=1)(x)\n",
    "    \n",
    "    key = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "    query = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "    value = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "    \n",
    "    score = tf.matmul(query, key, transpose_b=True)\n",
    "    score = tf.nn.softmax(score, axis=-1)\n",
    "    \n",
    "    out = tf.matmul(score, value, transpose_b=True)\n",
    "    out = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    out  = tf.Variable(0.5, trainable=True)*out\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x):\n",
    "    x = SpectralNormalization(Conv2DTranspose(x.shape[-1]*4, kernel_size=4, strides=2, padding='same'))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z_dims):\n",
    "    inp_ = Input(shape=(z_dims))\n",
    "    x = Dense(2*2*2)(inp_)\n",
    "    x = Reshape((2, 2, 2))(x)\n",
    "    for i in range(3):\n",
    "        x = upsample_block(x)\n",
    "    x = self_attention_block(x)\n",
    "    x = upsample_block(x)\n",
    "    x = self_attention_block(x)\n",
    "    x = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh')(x)\n",
    "    model = Model(inp_, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x):\n",
    "    x = SpectralNormalization(Conv2D(x.shape[-1]*4, kernel_size=4, strides=2, padding='same'))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(img_shape):\n",
    "    inp_ = Input(shape=img_shape)\n",
    "    x = inp_\n",
    "    for i in range(3):\n",
    "        x = downsample_block(x)\n",
    "    x = self_attention_block(x)\n",
    "    x = downsample_block(x)\n",
    "    x = self_attention_block(x)\n",
    "    x = Conv2D(1, kernel_size=4)(x)\n",
    "    x = tf.reshape(x, (-1,1))\n",
    "    x = tf.nn.softmax(x, axis=-1)\n",
    "    model = Model(inp_, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(generator, discriminator):\n",
    "    inp_ = Input(shape=(z_dims))\n",
    "    x = generator(inp_)\n",
    "#     discriminator.trainable = False\n",
    "    x = discriminator(x)\n",
    "    model = Model(inp_, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dims = 100\n",
    "image_shape = (64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = discriminator(image_shape)\n",
    "discriminator_model.compile(loss='hinge', optimizer=Adam(lr=4e-4, beta_1=0.0, beta_2=0.9), metrics=['accuracy'])\n",
    "\n",
    "generator_model = generator(z_dims)\n",
    "gan_model = gan(generator_model, discriminator_model)\n",
    "gan_model.compile(loss='hinge', optimizer=Adam(lr=1e-4, beta_1=0.0, beta_2=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generation():\n",
    "    z = np.random.normal(0, 1, (7*7, 100))\n",
    "    images = generator_model.predict(z)\n",
    "    images = images*0.5 + 0.5\n",
    "    fig, axis = plt.subplots(7, 7, figsize=(10, 10))\n",
    "    \n",
    "    num = 0\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            axis[i, j].imshow(images[num, :, :, :])\n",
    "            num += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        steps = len(image_path)//batch_size\n",
    "        for step in tqdm(range(steps)):\n",
    "            if (step+1)*batch_size > len(image_path):\n",
    "                batch_image_path = image_path[step*batch_size :]\n",
    "            else:\n",
    "                batch_image_path = image_path[step*batch_size: (step+1)*batch_size]\n",
    "            batch_images = data_loader(batch_image_path)\n",
    "            z = np.random.normal(0, 1, (batch_images.shape[0], 100))\n",
    "            \n",
    "            real_labels = np.ones((batch_images.shape[0], 1))*0.9\n",
    "            fake_labels = np.ones((batch_images.shape[0], 1))*0.0\n",
    "            \n",
    "            generated_image = generator_model.predict(z)\n",
    "            \n",
    "#             discriminator_model.trainable = True\n",
    "\n",
    "            real_images_loss, accuracy_real = discriminator_model.train_on_batch(batch_images, real_labels)\n",
    "            fake_images_loss, accuracy_fake = discriminator_model.train_on_batch(generated_image, fake_labels)\n",
    "            \n",
    "            loss = (real_images_loss + fake_images_loss)/2\n",
    "            accuracy = (accuracy_real + accuracy_fake)/2\n",
    "            \n",
    "            z = np.random.normal(0, 1, (batch_images.shape[0], 100))\n",
    "            \n",
    "#             discriminator_model.trainable = False\n",
    "            gan_loss, gan_accuracy = gan_model.train_on_batch(z, real_labels)\n",
    "            \n",
    "        np.random.shuffle(image_path)\n",
    "            \n",
    "        print(f'EPOCH {epoch} COMPLETE |  DISCRIMINATOR-LOSS = {loss} | DISCRIMINATOR-ACC {accuracy} | GAN-LOSS {gan_loss}' )\n",
    "        image_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_path = 'img_align_celeba'\n",
    "image_path = os.listdir(faces_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(batch_size, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
